{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cef5828a",
   "metadata": {},
   "source": [
    "# Generate Polar Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b57359",
   "metadata": {},
   "source": [
    "Change the importing of models and lists acording to which model you want to generate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de910e",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d0253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from numpy import linalg\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import time\n",
    "from random import shuffle\n",
    "import sys\n",
    "import nltk \n",
    "from nltk.corpus import wordnet \n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy\n",
    "import torch\n",
    "import subprocess\n",
    "\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ec4194",
   "metadata": {},
   "source": [
    "### Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d940e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gn = gensim.models.KeyedVectors.load_word2vec_format('/Users/stjepankusenic/POLAR_WEBE/data/raw/glove_norm_300.mod',binary=True)\n",
    "current_model = model_gn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f1483c",
   "metadata": {},
   "source": [
    "### Import Polar Dimension List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa7fc914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load original antonyms\n",
    "list_antonym = pd.read_pickle(r'/Users/stjepankusenic/POLAR_WEBE/data/interim/final_antonym_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579393ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load business antonym list\n",
    "list_new= [('product', 'service'),\n",
    "('essential', 'luxury'),\n",
    "('technical', 'natural'),\n",
    "('renewable', 'nonrenewable'),\n",
    "('advertising', 'secretive'),\n",
    "('lease', 'sell'),\n",
    "('tangible', 'intangible'),\n",
    "('demand', 'supply'),\n",
    "#('wfh', 'wfo'),\n",
    "('child', 'childless'),\n",
    "('remote', 'physical'),\n",
    "('salary', 'goodies'),\n",
    "('store', 'online'),\n",
    "('details', 'outlines'),\n",
    "('stakeholders', 'spectators'),\n",
    "('isolating', 'social'),\n",
    "('goal', 'task'),\n",
    "('employees', 'consultant'),\n",
    "('cost', 'revenue'),\n",
    "('seasonal', 'temporary'),\n",
    "('alliance', 'proprietorship'),\n",
    "('loss', 'profit'),\n",
    "('integrity', 'corruption'),\n",
    "('international', 'local'),\n",
    "('corporate', 'individual'),\n",
    "('order', 'disorder'),\n",
    "('solution', 'problem'),\n",
    "('manager', 'worker'),\n",
    "('diversity', 'uniformity'),\n",
    "('public', 'private'),\n",
    "('strategic', 'impulsive'),\n",
    "('innovator', 'follower'),\n",
    "('bankruptcy', 'prosperity'),\n",
    "('growth', 'decline'),\n",
    "('sustainable', 'unsustainable'),\n",
    "('family', 'work'),\n",
    "('criminal', 'rightful'),\n",
    "('financial', 'artisanal'),\n",
    "('supplier', 'purchaser'),\n",
    "('commitment', 'rejection'),\n",
    "('professional', 'amateur'),\n",
    "('independent', 'dependent'),\n",
    "('digital', 'analogue'),\n",
    "('marketing', 'secret'),\n",
    "('secure', 'risky'),\n",
    "('longterm', 'shortterm'),\n",
    "('responsible', 'neglect'),\n",
    "('ethical', 'unethical'),\n",
    "('beneficial', 'harmful'),\n",
    "('diversity', 'uniformity'),\n",
    "('trust', 'mistrust'),\n",
    "('teamwork', 'individualism'),\n",
    "('opportunity', 'threat'),\n",
    "('innovative', 'traditional'),\n",
    "('flexible', 'rigid'),\n",
    "('ambiguity', 'clarity'),\n",
    "('feminine', 'masculine'),\n",
    "('globally', 'locally'),\n",
    "('insiders', 'outsiders'),\n",
    "('foreigners', 'natives'),\n",
    "('minorities', 'majority'),\n",
    "('transparency', 'obscurity'),\n",
    "('discrimination', 'impartial'),\n",
    "('credible', 'deceptive'),\n",
    "('environment', 'pollution'),\n",
    "('pressure', 'relax'),\n",
    "('growth', 'decline'),\n",
    "('satisfied', 'unsatisfied'),\n",
    "('diplomatic', 'undiplomatic'),\n",
    "('motivate', 'demotivate'),\n",
    "('communicative', 'uncommunicative'),\n",
    "('connected', 'disconnected'),\n",
    "('autonomous', 'micromanagement'),\n",
    "('nurture', 'neglect'),\n",
    "('progressive', 'conservative'),\n",
    "('rewarding', 'unrewarding'),\n",
    "('bias', 'unbias'),\n",
    "('challenge', 'obscurity'),\n",
    "('collaboration', 'silo'),\n",
    "('outdated', 'modern'),\n",
    "('effortless', 'demanding'),\n",
    "('economic', 'overpriced'),\n",
    "('widespread', 'local'),\n",
    "('freedom', 'captive'),\n",
    "('consistent', 'inconsistent')]\n",
    "\n",
    "list_new= list(dict.fromkeys(list_new).keys())\n",
    "\n",
    "similarity_matrix = defaultdict(list)\n",
    "for each_pair in tqdm(list_new):\n",
    "    word1 = each_pair[0]\n",
    "    word2 = each_pair[1]\n",
    "    if word1 < word2:\n",
    "        similarity_matrix[word1].append(word2)\n",
    "    else:\n",
    "        similarity_matrix[word2].append(word1)\n",
    "\n",
    "all_similarity = defaultdict(dict)\n",
    "for each_key in tqdm(similarity_matrix):\n",
    "    for each_value in similarity_matrix[each_key]:\n",
    "#         cosine_similarity([current_model[each_key]]\n",
    "        all_similarity[each_key][each_value] = abs(cosine_similarity([current_model[each_key]],[current_model[each_value]])[0][0])\n",
    "\n",
    "final_list = []\n",
    "for index_counter, each_key in enumerate(tqdm(all_similarity)):\n",
    "#     print(each_key,all_similarity[each_key])\n",
    "    listofTuples = sorted(all_similarity[each_key].items() ,  key=lambda x: x[1])\n",
    "#     print(listofTuples)\n",
    "    final_list.append((each_key, listofTuples[0][0]))\n",
    "print(len(final_list))\n",
    "\n",
    "list_antonym = final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375b90ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(list_antonym)\n",
    "type(current_model[list_antonym[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bceb262",
   "metadata": {},
   "source": [
    "### Decide Polar Dimesion Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e30dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1468, 300)\n"
     ]
    }
   ],
   "source": [
    "num_antonym = 500\n",
    "\n",
    "## Find the antonym difference vectors\n",
    "antonymy_vector = []\n",
    "for each_word_pair in list_antonym:\n",
    "    if each_word_pair[0] in current_model.vocab:\n",
    "        if each_word_pair[1] in current_model.vocab:\n",
    "            antonymy_vector.append(current_model[each_word_pair[0]]- current_model[each_word_pair[1]])\n",
    "antonymy_vector = np.array(antonymy_vector)\n",
    "print(antonymy_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0855fb66",
   "metadata": {},
   "source": [
    "### Implement Dimesion Selection Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "572f67a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "t1 = np.array(antonymy_vector)\n",
    "dimension_similarity_matrix = scipy.spatial.distance.cdist(np.array(antonymy_vector),np.array(antonymy_vector),'cosine')\n",
    "dimension_similarity_matrix = abs(1-dimension_similarity_matrix)\n",
    "\n",
    "def get_set_score(final_list, each_dim):\n",
    "    final_output = 0.0\n",
    "    for each_vec in final_list:\n",
    "        final_output += dimension_similarity_matrix[each_vec][each_dim]\n",
    "    return final_output/(len(final_list))\n",
    "\n",
    "def select_subset_dimension(dim_vector, num_dim):\n",
    "    working_list = np.array(dim_vector)\n",
    "\n",
    "    working_position_index = [i for i in range(working_list.shape[0])]\n",
    "    final_position_index = []\n",
    "\n",
    "\n",
    "    print('working list is ready, shape', working_list.shape)\n",
    "    sel_dim = random.randrange(0, working_list.shape[0])\n",
    "\n",
    "    final_position_index.append(sel_dim)\n",
    "\n",
    "    working_position_index.remove(sel_dim)\n",
    "\n",
    "    for test_count in tqdm(range(num_dim-1)):\n",
    "        min_dim = None\n",
    "        min_score = 1000\n",
    "        for temp_index, each_dim in enumerate(working_position_index):\n",
    "            temp_score = get_set_score(final_position_index, each_dim)\n",
    "            if temp_score< min_score:\n",
    "                min_score= temp_score\n",
    "                min_dim = each_dim\n",
    "        final_position_index.append(min_dim)\n",
    "        working_position_index.remove(min_dim)\n",
    "    return final_position_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e91f4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embedding size is 1468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xy/yfm2dhtj3jvfy85hqy16wmk00000gn/T/ipykernel_42368/1149897526.py:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  current_model_tensor = torch.t(torch.tensor(current_model.wv.vectors))\n"
     ]
    }
   ],
   "source": [
    "embedding_size = antonymy_vector.shape[0]\n",
    "print('The embedding size is', embedding_size)\n",
    "\n",
    "\n",
    "variance_antonymy_vector_inverse = np.linalg.pinv(np.transpose(antonymy_vector))\n",
    "variance_antonymy_vector_inverse = torch.tensor(variance_antonymy_vector_inverse)\n",
    "\n",
    "embedding_matrix = []\n",
    "\n",
    "current_model_tensor = torch.t(torch.tensor(current_model.wv.vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "987c5e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = [None for x in range(20)] # variance for each antonym in each batch\n",
    "\n",
    "for i in range(19):  # the first 19 batches, each of size 100k\n",
    "  temp = torch.matmul(variance_antonymy_vector_inverse, current_model_tensor[:,100000*i:100000*i+100000])\n",
    "  temp_var_mean = torch.var(temp, axis = 1)\n",
    "  var_list[i] = temp_var_mean.numpy()\n",
    "  del temp\n",
    "\n",
    "temp = torch.matmul(variance_antonymy_vector_inverse, current_model_tensor[:,1900000:])\n",
    "temp_var_mean = torch.var(temp, axis = 1)\n",
    "var_list[19] = temp_var_mean.numpy()\n",
    "del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0169b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using lazy approach. assume each batch is independent and the overall variance is the average variance over all batches\n",
    "\n",
    "variance_list = np.mean(np.array(var_list),axis = 0)\n",
    "\n",
    "variance_antonymy_vector = [each for each in sorted(range(len(variance_list)), key=lambda i: variance_list[i], reverse=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3d4640",
   "metadata": {},
   "source": [
    "### Import business entity names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60602bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "company = pd.read_csv('/Users/stjepankusenic/POLAR_WEBE/data/raw/International_Fortune_GloVe.csv')\n",
    "name_list = company['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1603f282",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_word_embedding = dict()\n",
    "for name in name_list:\n",
    "    name_word_embedding[name] = current_model[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a30e10",
   "metadata": {},
   "source": [
    "### Create Polar Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a73ae1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_antonym_space(current_model, output_file_path, binary, current_antonymy_vector_inverse):\n",
    "\n",
    "    temp_dict = dict()\n",
    "\n",
    "    embedding_size = current_antonymy_vector_inverse.shape[0]   ##CHANGE THIS ACCORDINGLY!!!\n",
    "    print('New model size is',len(current_model), embedding_size)\n",
    "\n",
    "    temp_file = None\n",
    "\n",
    "    if binary:\n",
    "        temp_file = open(output_file_path,'wb')\n",
    "        temp_file.write(str.encode(str(len(current_model))+' '+str(embedding_size)+'\\n'))\n",
    "    else:\n",
    "        temp_file = open(output_file_path,'w')\n",
    "        temp_file.write(str(len(current_model))+' '+str(embedding_size)+'\\n')\n",
    "\n",
    "    total_words = 0\n",
    "    for each_word in tqdm(current_model):\n",
    "        total_words += 1\n",
    "        if binary:\n",
    "            temp_file.write(str.encode(each_word+' '))\n",
    "        else:\n",
    "            temp_file.write(each_word+' ')\n",
    "\n",
    "        new_vector = np.matmul(current_antonymy_vector_inverse,current_model[each_word])\n",
    "\n",
    "        new_vector = new_vector/linalg.norm(new_vector)\n",
    "        temp_dict[each_word] = new_vector\n",
    "\n",
    "        if binary:\n",
    "            temp_file.write(new_vector)\n",
    "            temp_file.write(str.encode('\\n'))\n",
    "        else:\n",
    "            temp_file.write(str(new_vector))\n",
    "            temp_file.write('\\n')\n",
    "\n",
    "\n",
    "    temp_file.close()\n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35cc5ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding_path(current_model, embedding_path, binary, antonym_vector, curr_dim):\n",
    "    curr_antonym_vector = antonymy_vector[antonym_vector[:curr_dim]]\n",
    "    curr_antonymy_vector_inverse = np.linalg.pinv(np.transpose(curr_antonym_vector))\n",
    "    new_embedding_dict = transform_to_antonym_space(current_model, embedding_path, binary,curr_antonymy_vector_inverse)\n",
    "\n",
    "    return new_embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d2ac3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size = 500 # Number of POLAR dimenions\n",
    "antonym_vector_method = variance_antonymy_vector\n",
    "# random_antonym_vector or orthogonal_antonymy_vector or variance_antonymy_vector\n",
    "antonym_500 = [list_antonym[x] for x in antonym_vector_method[:500]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eed552c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model size is 167 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xy/yfm2dhtj3jvfy85hqy16wmk00000gn/T/ipykernel_42368/2385129348.py:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for each_word in tqdm(current_model):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48116213c2a1438591089563dfe815f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create POLAR embedding of names\n",
    "name_new_embedding = generate_embedding_path(name_word_embedding, 'name_embeddings',True ,antonym_vector_method,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eeac49ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_polar_dict(company_name, antonym, embedding, top_n = False, n = 10):\n",
    "  temp_dict = dict()\n",
    "  temp_polar = embedding[company_name]\n",
    "\n",
    "  if top_n:\n",
    "    idx = np.argsort([abs(x) for x in temp_polar])[-n:]\n",
    "    for i in idx:\n",
    "      print(antonym[i],temp_polar[i],'\\n')\n",
    "\n",
    "\n",
    "  if len(antonym) == len(temp_polar):\n",
    "    for a in range(len(antonym)):\n",
    "      temp_dict[antonym[a]] = temp_polar[a]\n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf67e72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('follower', 'innovator') 0.09955804 \n",
      "\n",
      "('critique', 'guess') 0.106556386 \n",
      "\n",
      "('bragging', 'humble') 0.108869635 \n",
      "\n",
      "('sign', 'talk') 0.11223837 \n",
      "\n",
      "('comply', 'helm') 0.12356726 \n",
      "\n",
      "('chapter', 'page') -0.12495641 \n",
      "\n",
      "('supervised', 'unsupervised') -0.12506409 \n",
      "\n",
      "('australian', 'kiwi') -0.12907332 \n",
      "\n",
      "('disclose', 'secrete') 0.13103342 \n",
      "\n",
      "('ceo', 'workforce') 0.14726065 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "facebook_polar = make_polar_dict('facebook', antonym_500, name_new_embedding, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f693f12c",
   "metadata": {},
   "source": [
    "### Save the Polar Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b657075",
   "metadata": {},
   "outputs": [],
   "source": [
    "###make csv###\n",
    "# download csv\n",
    "\n",
    "df = dict()\n",
    "for t in name_list:\n",
    "  df[t] = make_polar_dict(t, antonym_500, name_new_embedding)\n",
    "\n",
    "new_df = pd.DataFrame(df).transpose()\n",
    "\n",
    "# change columns to better read names\n",
    "new_columns = []\n",
    "\n",
    "for pair in antonym_500:\n",
    "  temp = pair[0]+''+pair[1]\n",
    "  new_columns.append(temp)\n",
    "\n",
    "new_df.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab080fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('POLAR-GloVeWiki-org-antonyms-inter.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56abde90",
   "metadata": {},
   "source": [
    "#### Next up generate insights with the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
